{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqh_NMwMjfhO"
   },
   "source": [
    "# Домашняя работа"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Сделайте mapper и reducer, чтобы посчитать среднее и дисперсию оценок за фильм."
   ],
   "metadata": {
    "id": "dSCZYSMrTtEM"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Реализация через цикл (предпогаем, что мы не знаем сколько у нас фильмов):"
   ],
   "metadata": {
    "id": "g6AlGOz7aws5"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T17:40:35.347163Z",
     "start_time": "2024-07-08T17:40:35.342570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from functools import reduce\n",
    "from joblib import Parallel, delayed"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "n, mean, M2 = 0, 0.0, 0\n",
    "for path in Path(\"les/imdb-user-reviews\").glob(\"**/*\"):\n",
    "    if path.is_file() and path.suffix == \".json\":\n",
    "        with open(path, \"r\") as f:\n",
    "            info = json.load(f)\n",
    "        score = float(info[\"movieIMDbRating\"])\n",
    "        n += 1\n",
    "        delta = score - mean\n",
    "        mean += delta / n\n",
    "        M2 += delta * (score - mean)\n",
    "\n",
    "print(mean, (M2 / n) ** (1 / 2))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yBhMEH50MCyf",
    "outputId": "c7b71698-ea06-4ef8-929e-95f18e9b3e7e",
    "ExecuteTime": {
     "end_time": "2024-07-08T17:40:35.400597Z",
     "start_time": "2024-07-08T17:40:35.385173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.03 1.0517128885774865\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 9 ms\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "На основе этого кода соберите mapper и reducer:"
   ],
   "metadata": {
    "id": "Ic09ccPLbMUR"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T17:48:32.104170Z",
     "start_time": "2024-07-08T17:48:32.097398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mapper(path):\n",
    "    # Ваш код\n",
    "    with open(path, \"r\") as f:\n",
    "        info = json.load(f)\n",
    "    score = float(info[\"movieIMDbRating\"])\n",
    "    return 1, score, 0.0\n",
    "\n",
    "\n",
    "def reducer(score_data1, score_data2):\n",
    "    #  Ваш код\n",
    "    n1, mean1, M2_1 = score_data1\n",
    "    n2, mean2, M2_2 = score_data2\n",
    "\n",
    "    n = n1 + n2\n",
    "    if n == 0:\n",
    "        return 0, 0.0, 0.0\n",
    "\n",
    "    delta = mean2 - mean1\n",
    "    # delta = (mean2 * n2 - mean1 * n1) / n\n",
    "    mean = mean1 + delta * n2 / n\n",
    "    M2 = fsum([M2_1, M2_2, delta**2 * n1 * n2 / n])\n",
    "    return n, mean, M2"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T17:48:32.331385Z",
     "start_time": "2024-07-08T17:48:32.319355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "n, mean, M2 = reduce(\n",
    "    reducer, map(mapper, Path(\"les/imdb-user-reviews\").rglob(\"*.json\"))\n",
    ")\n",
    "print(mean, (M2 / n) ** (1 / 2))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.03 1.0517128885774865\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 7 ms\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T18:19:38.037941Z",
     "start_time": "2024-07-08T18:19:37.416954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "n, mean, M2 = reduce(\n",
    "    reducer,\n",
    "    Parallel(n_jobs=2)(\n",
    "        delayed(mapper)(path) for path in Path(\"les/imdb-user-reviews\").rglob(\"*.json\")\n",
    "    ),\n",
    ")\n",
    "print(mean, (M2 / n) ** (1 / 2))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.03 1.0517128885774865\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 615 ms\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Из приведенных выше результатов можно сделать следующие наблюдения:**\n",
    "\n",
    "1. **Результаты расчетов**:\n",
    "   - Среднее значение оценки фильмов: **8.03**\n",
    "   - Стандартное отклонение: **1.0517128885774865**\n",
    "\n",
    "2. **Время выполнения**:\n",
    "   - Вариант с использованием `reduce` и `map`: \n",
    "     - CPU время: **46.9 ms**\n",
    "     - Время на стенке (Wall time): **7 ms**\n",
    "   - Вариант с использованием `reduce` и `Parallel` из `joblib`:\n",
    "     - CPU время: **46.9 ms**\n",
    "     - Время на стенке (Wall time): **615 ms**\n",
    "\n",
    "3. **Анализ производительности**:\n",
    "   - Вариант с `reduce` и `map` оказался более эффективным с точки зрения общего времени выполнения (Wall time).\n",
    "   - Использование параллелизации с помощью `Parallel(n_jobs=2)` из библиотеки `joblib` привело к значительному увеличению времени на стенке (Wall time) до **615 ms** по сравнению с **7 ms** в первом варианте, несмотря на одинаковое CPU время (**46.9 ms**).\n",
    "   - Это может быть связано с накладными расходами на создание и управление параллельными задачами, которые могут превысить выгоду от параллелизации, особенно на небольших объемах данных.\n",
    "\n",
    "4. **Рекомендации**:\n",
    "   - Для данной задачи использование простого `reduce` и `map` кажется более эффективным и быстрым решением.\n",
    "   - Параллелизация может быть полезной при обработке больших объемов данных или при наличии значительного количества вычислительных задач, но в данном случае, на небольших объемах данных, она оказывается менее эффективной.\n",
    "\n",
    "Следовательно, для текущей задачи рекомендуется использовать первый вариант с `reduce` и `map` для более быстрого выполнения.\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Увеличим количество данных"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T18:26:04.317330Z",
     "start_time": "2024-07-08T18:21:45.768636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "n, mean, M2 = reduce(\n",
    "    reducer, map(mapper, list(Path(\"les/imdb-user-reviews\").rglob(\"*.json\")) * 100000)\n",
    ")\n",
    "print(mean, (M2 / n) ** (1 / 2))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.03000000000032 1.0517128885774976\n",
      "CPU times: total: 4min 18s\n",
      "Wall time: 4min 18s\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T18:20:14.322692Z",
     "start_time": "2024-07-08T18:20:13.108090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "n, mean, M2 = reduce(\n",
    "    reducer,\n",
    "    Parallel(n_jobs=2)(\n",
    "        delayed(mapper)(path) for path in Path(\"les/imdb-user-reviews\").rglob(\"*.json\")\n",
    "    )\n",
    "    * 100000,\n",
    ")\n",
    "print(mean, (M2 / n) ** (1 / 2))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.03000000000032 1.0517128885774976\n",
      "CPU times: total: 1.22 s\n",
      "Wall time: 1.21 s\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Из приведенных выше результатов можно сделать следующие наблюдения:**\n",
    "\n",
    "1. **Время выполнения**:\n",
    "   - Вариант с использованием `reduce` и `map` на большом количестве данных (100,000 повторов):\n",
    "     - CPU время: **4 минуты 18 секунд**\n",
    "     - Время на стенке (Wall time): **4 минуты 18 секунд**\n",
    "   - Вариант с использованием `reduce` и `Parallel` из `joblib` на том же количестве данных:\n",
    "     - CPU время: **1.22 секунды**\n",
    "     - Время на стенке (Wall time): **1.21 секунды**\n",
    "\n",
    "2. **Анализ производительности**:\n",
    "   - В первом варианте с `reduce` и `map` время выполнения значительно увеличилось до более чем 4 минут при обработке 100,000 повторов данных. Это связано с последовательной обработкой большого объема данных.\n",
    "   - Во втором варианте с `reduce` и `Parallel` время выполнения существенно сократилось до чуть более 1 секунды для тех же 100,000 повторов данных. Это показывает значительное преимущество параллельной обработки при больших объемах данных.\n",
    "\n",
    "3. **Рекомендации**:\n",
    "   - Для обработки большого объема данных (таких как 100,000 повторов в данном примере) использование параллелизации с помощью `joblib` оказывается гораздо более эффективным, значительно сокращая как CPU время, так и время на стенке.\n",
    "   - Параллелизация позволяет существенно ускорить выполнение задач за счет распределения нагрузки между несколькими процессорами, что особенно заметно на больших объемах данных.\n",
    "\n",
    "Следовательно, для больших объемов данных рекомендуется использовать второй вариант с параллелизацией (`reduce` и `Parallel` из `joblib`), так как он обеспечивает значительное улучшение производительности по сравнению с последовательной обработкой."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
